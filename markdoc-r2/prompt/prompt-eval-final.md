# 任务评估指令

## 评估步骤

### 1. 代码验证
- **运行项目**：不对代码做任何修改，直接运行并验证功能
- **记录问题**：如有报错，分析根本原因并详细记录
- **测试验证**：根据需要运行单元测试或构建集成测试

### 2. 对照任务要求
参考 `scoring-criteria.md`，评估代码对 `/task_data/content.json` 中 `prompt` 字段任务的完成情况。

### 3. 分析执行记录
- **工具调用统计**：阅读 `record-*.md`，统计各类工具的使用次数和成功率  
  - 搜索 `toolName` 关键字统计工具调用  
  - 搜索 `status: success` 统计成功次数  
  - 计算成功率并列出具体数据  
- **Model Breaking 分析**：如触发 breaking，定位具体位置并分析原因

## 评分字段与输出格式（合并自 evaluation-template.md）

### 需填写的字段（写入 `content.json`，每项≤150字）

需要按如下键写入纯文本内容：

- `good`：3 条现有代码的优点  
- `modelDid`：模型实现的功能
- `交付完整性`  
- `工具调用`  
- `错误修复`  
- `上下文理解`  
- `用户体验`

### 文本格式要求

- 使用**纯文本**，不要使用任何 markdown 语法（如 `**`、`#`、反引号等）。  
- **换行统一使用 `\n`** 表示，而不是真实换行。  
- 内部字段的内容不使用 JSON 数组结构，如果原本是列表，用 `\n` 连接为单个字符串。  
- 参考模版（以“交付完整性”为例）：

已实现需求：\n1. 功能点A完全实现\n2. 功能点B符合要求\n\n未完整实现或存在严重问题：\n1. 缺少单元测试\n2. 数据库脚本不匹配\n - name.java和name.sql字段冲突 \n3. 编译失败 \n - name.java 存在报错 \n评分理由：根据“交付物具备可行性，但未达成主要需求”，给予3分。

## 评估原则
- **客观公正**：严格依据评分标准，在评分语句中引用。  
- **有理有据**：每个评分点必须有具体证据支撑，指出文件或函数名称。  
- **评分一致**：描述给出的理由必须与打分高低匹配，避免前后矛盾。

## 调整顺序
将 `/task_data/content.json` 中字段顺序调整为：

sessionID, prompt, originalRepo, repoDscb, githubPR, msnDscb, steps, modelDid, failure, good, 交付完整性, 工具调用, 错误修复, 上下文理解, 用户体验, traeID, usrID

同时需满足：

- 所有文本字段中的换行使用 `\n` 表示  
- 字段内容不为 JSON 数组，将数组统一转换为由 `\n` 分隔的单个字符串
- 如存在错误，修复
- 不得缺失字段，如果缺失，请指出

