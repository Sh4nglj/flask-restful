# 评分标准

## 打分四要素

1. **细节清晰**：要细节的描述，打分内容要指向具体内容  
2. **遵循标准**：打分要严格参考上方的「打分标准」表格，强烈建议套用「打分标准」中的话术  
3. **评分与描述要一致**：不要出现分打得高但是评论中指出了多个缺点，造成了前后不一致的困惑  

## Model Breaking

模型在完成任务时是否出现 必须人工介入 或 任务不可用 的情况  

- 需要人工介入无法独立完成任务：称之为"触发了 Model Breaking"  。  
- 例如  
  - "模型思考次数已达上限，请输入"继续"后获得更多结果。"  
  - 生成的代码编译失败。  
- 无需人工介入、较好的完成任务：未触发 Model Breaking

## 打分标准

### 交付完整性

#### 描述

需求功能点实现完整，符合用户预期

#### 5分

交付物不仅实现了全部需求，还根据需求完善了隐性需求

#### 4分

交付物实现了全部需求

#### 3分

• 交付物实现了主要需求  
• 非代码交付物的解答解决了用户的主要问题，但内容略显简略

#### 2分

• 交付物具备可行性，但未达成主要需求。  
• 交付物因环境依赖问题无法运行，不计代码内容  
• 非代码交付物的回答偏离主题，缺乏针对性，未直接解决用户主要问题。

#### 1分

• 代码交付物编译失败，且代码内部频繁出现错误，致使无法运行  
• 非代码交付物的回答偏离主题，未能解决用户的主要问题

### 工具调用

#### 描述

识别何时需要工具（如查看文件、CLI指令、浏览器使用、联网搜索等）并有效使用这些工具的能力的评估。  
统计工具调用的成功率，需要列出具体的次数和成功率。  
工具调用为``toolName``关键字。成功为`status: success`

#### 5分

自主调用合适的工具并完美使用

#### 4分

能正确使用工具，但存在轻微的效率问题或～10%的调用失败。

#### 3分

工具调用存在20%～50%的失败。

#### 2分

工具选择不当或50%以上工具调用被错误使用。

#### 1分

即使必要时也无法使用工具。

### 错误修复

#### 描述

识别、诊断并修复自身错误或用户代码中错误的能力。

#### 5分

检测到了错误且在第一次尝试就完成了修复，并验证了修复效果

#### 4分

检测到了错误并立刻完成了错误修复

#### 3分

检测到了错误并在多次尝试内完成了修复

#### 2分

检测到了错误，但最终没有完成修复

#### 1分

完全忽略了错误

### 上下文理解

#### 描述

评估模型在回复中读取、分析现有上下文并将其整合的能力。

#### 5分

能够准确、精炼地整合全部上下文，保留所有关键信息并得出正确结论，同时遵循指令且思路连贯。

#### 4分

能够整合上下文内容，遵循指令并不遗漏关键信息，给出正确的结论。思维链偶有冗余。

#### 3分

能够整合大部分上下文内容，但在信息传递过程中丢失细节或误导；可能存在轻微指令偏离或规划不当。

#### 2分

误解部分上下文内容，致使模型遗漏关键信息，造成思维链存在重大缺失

#### 1分

完全忽略或错误解读上下文，致使模型思维中断或违反硬性约束条件的步骤

### 用户体验

#### 描述

从用户视角评估模型在整个交互与输出过程中的体验质量。

#### 5分

模型推理高效流畅、结构清晰、几乎无停顿或自纠环节，且能迅速抓住问题核心。输出结果让人愉快且可信，几乎无改进空间。

#### 4分

模型整体体验良好，偶有轻微冗余操作或自我修正，但不影响对任务的完成。

#### 3分

模型整体体验尚可，存在轻微冗余；偶有简单问题复杂化；用户仍有意愿等待模型结果。

#### 2分

模型推理过程拖沓，反复纠正或出现明显逻辑错误。如：简单问题复杂化；用户仍能从中筛选出正确信息。

#### 1分

模型推理过程极度繁琐或陷入死循环且无自我修复能力，严重影响用户体验且没有任何有效输出。

